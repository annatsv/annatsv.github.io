<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Anna Tsvetkov</title>
  <meta name="keywords" content="Anna Tsvetkov, Anna Tsvetlkov Brown, Anna Tsvetkov Princeton, Anna Tsvetkov Philosophy">
  <meta name="description" content="Anna Tsvetkov, Personal Website">
  <meta name="author" content="Anna Tsvetkov">

  <!-- Bootstrap Core CSS -->
  <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom CSS -->
  <link href="css/custom.css" rel="stylesheet">

  <!-- Font Awesome -->
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <!-- jQuery & Bootstrap JS (only once) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
</head>

<body id="page-top" class="index">
  <!-- Portfolio -->
  <section id="portfolio">
    <div class="container">


<!-- Hero header -->
<!-- Hero header -->
<div class="row header-hero">
  <div class="col-sm-7">
    <h2 class="title">Anna<br>Tsvetkov</h2>
  </div>
  <div class="col-sm-5 text-right">
  </div>
</div>





<!-- Bio + Portrait -->
<div class="row">
  <div class="col-sm-7">
    <div class="info">
      <!-- all your bio paragraphs -->
      <p class="margin-top-xs intro">
        I am a Philosophy PhD and Computer Science (AI/ML) ScM student at
        <a href="https://philosophy.brown.edu/people" target="_blank"><strong>Brown</strong></a>. I work with
        <a href="https://sites.google.com/view/adampautz/home" target="_blank"><strong>Adam Pautz</strong></a>,
        <a href="https://cs.brown.edu/people/epavlick/" target="_blank"><strong>Ellie Pavlick</strong></a>,
        <a href="https://vivo.brown.edu/display/cshill#" target="_blank"><strong>Chris Hill</strong></a>,
        and <a href="https://consc.net/" target="_blank"><strong>David Chalmers</strong></a>.
      </p>
      <p class="margin-top-xs intro">
        I am also an AI researcher at
        <a href="https://futuretech.mit.edu/" target="_blank"><strong>MIT FutureTech</strong></a>. In the Fall, I will be an AI Postdoctoral Research Fellow at
        <a href="https://ai.princeton.edu/ai-lab" target="_blank"><strong>Princeton</strong></a>.
      </p>
      <p class="margin-top-xs intro">
        My research focuses on human-centered AI. The goal of my work is to use philosophy to guide experiments on AI that deepen our understanding of the mind and, in turn, to use insights about the mind to build explainable and ethical AI.
      </p>
      <p class="margin-top-xs intro">
        You can email me at anna_tsvetkov [at] brown.edu.
      </p>
      <p class="intro">
        <a class="cv" href="about/abhraneel_cv.pdf" target="_blank">CV <i class="fa fa-long-arrow-right"></i></a>
      </p>
    </div>
  </div>
  <div class="col-sm-5">
    <img src="img/social/tsvetkov.jpg"
         alt="Anna Tsvetkov"
         class="img-responsive img-circle bio-photo">
  </div>
</div>

                  
<!-- NEWS -->
<div class="row margin-top-md">
  <div class="col-sm-7">
    <div class="projects"><h2 class="section-title">News</h2></div>
    <div class="row margin-top-sm">
      <div class="col-sm-2 news-date">
        <strong>May 2026</strong>
      </div>
      <div class="col-sm-10">
        <p class="news-text">
          Pleased to share that I will be speaking at the
          <a href="https://philevents.org/event/show/137714" target="_blank">
            <strong>Bilkent-UNAM Philosophy of Mind Conference</strong>.
          </a>
        </p>
      </div>
    </div>
  </div>
</div>




<!-- Publications -->
<div class="row margin-top-md">
  <div class="col-sm-7">
    <div class="projects">
      <h2 class="section-title">Publications</h2>
    </div>
    <p class="margin-top-sm">
      <span class="paper-title">
        <a
          href="https://annatsv.github.io/pubs/Can_We_Interpret_Artificial_Neural_Net_works_As_Having_Beliefs_and_Desires.pdf"
          target="_blank"
        >
          Can We Interpret Artificial Neural Networks As Having Beliefs and Desires?
        </a>
      </span>
      <br>
      <span class="authors">
        <span class="self">Anna Tsvetkov</span><br>
  <span class="venue">British Journal of the Philosophy of Science (forthcoming)</span><br>
          <a
            href="https://annatsv.github.io/pubs/Can_We_Interpret_Artificial_Neural_Net_works_As_Having_Beliefs_and_Desires.pdf"
            target="_blank"
          >
            <i
              class="fa fa-file-o"
              style="font-size:1em; line-height:1em; margin-right:4px; position:relative; top:-1.9px;"
            ></i>
            PDF
          </a>
          &nbsp;&bull;&nbsp;
          <a
            data-toggle="collapse"
            href="#abstract1"
            aria-expanded="false"
            aria-controls="abstract1"
            class="abstract-toggle"
          >
            Abstract
          </a>
        </span>
      </span>
    </p>
    <div class="collapse" id="abstract1" style="margin-top:10px;">
      <p class="abstract-text">
        Can we interpret the internal workings of artificial neural networks in terms of beliefs and desires? A central aim in mechanistic interpretability is to explain the inner workings of artificial neural networks in terms that we can understand. Since we explain human beings in terms of beliefs and desires, it is natural to ask whether we can explain artificial neural networks in these terms too. In recent work, David Chalmers (2025) proposes <em>propositional interpretability</em> as an important approach within mechanistic interpretability, arguing that the computational states of artificial neural networks can be explained in terms of propositional attitudes—states like beliefs, desires, and subjective probabilities to propositions. This paper examines the prospects for propositional interpretability as a framework for explaining the internal workings of artificial neural networks. I draw attention to a number of empirical and methodological problems with propositional interpretability that are based on a philosophical gloss of recent f indings in the mechanistic interpretability literature. Some of these challenges, such as determining whether artificial neural networks encode propositions rather than unbound concepts, might be mitigated through new interpretability techniques and open up exciting avenues for future research. Other problems, including reliably mapping computational states to propositional attitudes and managing an explosion of potential propositional interpretations, present serious difficulties for the approach. The challenges should be of interest both to philosophers seeking to engage with empirical work in mechanistic interpretability and to neural network researchers aiming to develop novel interpretability methods informed by philosophical insights.
      </p>
    </div>
  </div>
</div>


<!-- Works in Progress -->
<div class="row margin-top-md">
  <div class="col-sm-7">
    <div class="projects">
      <h2 class="section-title">Works in Progress</h2>
    </div>
    <p class="margin-top-sm">
      <span class="paper-title">Can Large Language Models Represent Perceptual Reality?</span><br>
      <span class="paper-title">Molyneux’s Question and Multimodal Models</span><br>
      <span class="paper-title">Scientific Use of Foundation Models and Democratization of AI</span><br>
      <span class="paper-details" style="font-size:18px; line-height:1.6;">
        (In collaboration with 
          <a href="https://futuretech.mit.edu/" target="_blank">MIT FutureTech</a>)
      </span>
    </p>
  </div>
</div>
